{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Импорт библиотек\n",
    "import pandas as pd\n",
    "from pandas import Series\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import datetime as dt\n",
    "import missingno as msno\n",
    "%matplotlib inline\n",
    "from sklearn.feature_selection import f_classif, mutual_info_classif\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "from sklearn.metrics import auc, roc_auc_score, roc_curve, precision_recall_curve, average_precision_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Импорт данных и \"предполетная\" подготовка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'train.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-f313a9dec0a4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#Импортируем данные\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mdf_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'train.csv'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'ISO-8859-1'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlow_memory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mdf_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'test.csv'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'ISO-8859-1'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlow_memory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    674\u001b[0m         )\n\u001b[0;32m    675\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 676\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    678\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    446\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    447\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 448\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    449\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    450\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    878\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    879\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 880\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    881\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    882\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1112\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"c\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1113\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"c\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1114\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1115\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1116\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"python\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1872\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"compression\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1873\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1874\u001b[1;33m                 \u001b[0msrc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"rb\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1875\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1876\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'train.csv'"
     ]
    }
   ],
   "source": [
    "#Импортируем данные\n",
    "\n",
    "df_train = pd.read_csv('train.csv', encoding = 'ISO-8859-1', low_memory = False)\n",
    "df_test = pd.read_csv('test.csv', encoding = 'ISO-8859-1', low_memory = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Чтобы можно было производить обработку всех данных сразу, объединим датасеты в один и пометим бинарными ключами. \n",
    "# По этим клшючам потом спокойно разделим его обратно\n",
    "df_train['sample'] = 1 \n",
    "df_test['sample'] = 0 \n",
    "df_test['default'] = 0 # мы должны предсказать default, поэтому пока просто заполняем тестовую часть нулями\n",
    "\n",
    "df = df_test.append(df_train, sort=False).reset_index(drop=True) # объединяем\n",
    "\n",
    "print(df_train.shape)\n",
    "print(df_test.shape)\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Также сразу зафиксируем Random_seed для воспроизводимости экспериментов\n",
    "RANDOM_SEED = 42 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Используемые функции и классы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Класс для работы с выбросами. Умеет выдавать информацию по кол-ву выбросов в стобцах, \n",
    "# показывать боксплоты и удалять выбросы. \n",
    "\n",
    "# P.S. Изначально в этом классе я просто забыл везде указывать Self, однако он работает и без этого. \n",
    "#      Если будет возможность, укажите пожалуйста в рецензии, почему.\n",
    "class outliers():\n",
    "    def find(df): #метод для поиска и вывода информации о выбросах\n",
    "        print(df.describe())\n",
    "        for col in df.columns:\n",
    "            if df[col].dtype != 'O':\n",
    "                counter = 0\n",
    "                Q1 = df[col].quantile(0.25)\n",
    "                Q3 = df[col].quantile(0.75)\n",
    "                IQR = Q3 - Q1\n",
    "                for string in df[col]:\n",
    "                    if (string < (Q1 - 1.5 * IQR) or string > (Q3 + 1.5 * IQR)):\n",
    "                        counter += 1\n",
    "                print('количество выбросов в столбце {}'.format(col), '-', counter)\n",
    "                \n",
    "    def show(df): #метод для отображения выбросов в виде боксплотов\n",
    "        fig, axes = plt.subplots(figsize=(40, 20))\n",
    "        df.boxplot()\n",
    "        \n",
    "    def delete(df): #метод для удаления выбросов\n",
    "        for col in df.columns:\n",
    "            if df[col].dtype != 'O':\n",
    "                Q1 = df[col].quantile(0.25)\n",
    "                Q3 = df[col].quantile(0.75)\n",
    "                IQR = Q3 - Q1\n",
    "                for string in df[col]:\n",
    "                    if (string < (Q1 - 1.5 * IQR) or string > (Q3 + 1.5 * IQR)):\n",
    "                        df = df.drop(df[df[col] == string].index)\n",
    "        return df\n",
    "\n",
    "#Функция для превращения признака app_data в набор отдельных признаков:\n",
    "def extract_datetime_features(df,datetime_col_name='app_date'):\n",
    "    results = {}\n",
    "    start = df[datetime_col_name].min()\n",
    "    results['month'] = df[datetime_col_name].dt.month\n",
    "    results['day'] = df[datetime_col_name].dt.day\n",
    "    results['week'] = df[datetime_col_name].dt.week\n",
    "    results['dayofweek'] = df[datetime_col_name].dt.dayofweek\n",
    "    results['dayofyear'] = df[datetime_col_name].dt.dayofyear\n",
    "    results['quarter'] = df[datetime_col_name].dt.quarter\n",
    "    results['weekofyear'] = df[datetime_col_name].dt.weekofyear\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Просмотр данных, работа над пропусками"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Теперь посмотрим, есть ли пропущенные значения в данных\n",
    "display(msno.matrix(df))\n",
    "display(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Как видно,пропусков немного. Они встречаются только в столбце Education. \n",
    "#Посмотрим,как распределяются данные в этом столбце чтобы понять, как их обработать.\n",
    "df['education'].value_counts().plot.barh()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Судя по диаграммам, можно заполнить пропуски в столбце Education\n",
    "# самым часто встречюащимся значением, т.е SCH.\n",
    "df['education'] = df['education'].fillna('SCH')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Также сразу посмотрим, можно ли отбросить какие-то признаки из-за сильной корреляции:\n",
    "plt.figure(figsize=(10,5))\n",
    "sns.heatmap(df.corr().abs(), vmin=0, vmax=1, annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# work_address и home_address имеют самую высокую степень корреляции. \n",
    "# Также сильно скореллированы sna и first_time.\n",
    "# Удалим work_address. first_time и sna удалять не будем, они важны.\n",
    "\n",
    "df = df.drop(['work_address'],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Обработка признака Client_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Сразу выделим из тестовых данных признак client_id в отдельную переменную.\n",
    "#Для клиентских id мы в конечном итоге и будем делать прогноз, а пока из самих датасетов\n",
    "#его уберем.\n",
    "clients = df['client_id']\n",
    "df = df.drop(['client_id'],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Обработка признака app_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#В том формате, в котором дата обращения представлена по умолчанию, ничего сделать с ней не плучится.\n",
    "df['app_date'].head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Для этого сначала преобразуем этот признак в формат datetime\n",
    "df['app_date'] = pd.to_datetime(df['app_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#А затем с помощью функции extract_datetime_features разобьем признак app_date на субпризнаки:\n",
    "#1) Месяц обращения\n",
    "#2) День обращения\n",
    "#3) Неделя обращения\n",
    "#4) день недели обращения\n",
    "#5) День года обращения\n",
    "#6) Квартал\n",
    "#7) Неделя года обращения\n",
    "    \n",
    "for k,v in extract_datetime_features(df).items():\n",
    "    df[k]=v\n",
    "df.drop(labels=['app_date'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Разбиение признаков по группам."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Разобьем переменные по группам\n",
    "bin_cols = ['sex','car','car_type','good_work','foreign_passport']\n",
    "cat_cols = ['education','home_address']\n",
    "num_cols = ['age','decline_app_cnt','income','bki_request_cnt']\n",
    "\n",
    "#Признаки, получившиеся в результате преобразования даты, выделим в отдельную категорию\n",
    "date_cols = ['month','day','week','dayofweek','dayofyear','quarter','weekofyear'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Обработка бинарных признаков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Для бинарных признаков мы будем использовать LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "for column in bin_cols:\n",
    "    df[column] = label_encoder.fit_transform(df[column])\n",
    "\n",
    "# то же самое сделаем для признака education\n",
    "df['education'] = label_encoder.fit_transform(df['education'])\n",
    "# убедимся в преобразовании    \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Обработка категориальных признаков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Категориальные признаки можно просто преобразовать в Dummies\n",
    "df = pd.get_dummies(df,columns=['education','home_address'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Обработка числовых признаков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cмотрим на распределения числовых признаков в тренировочных данных. \n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(17, 15))\n",
    " \n",
    "axes[0][0].hist(df['age'])\n",
    "axes[0][0].set_title('Возраст')\n",
    "\n",
    "axes[0][1].hist(df['decline_app_cnt'])\n",
    "axes[0][1].set_title('количество отказанных прошлых заявок')\n",
    "\n",
    "axes[1][0].hist(df['income'])\n",
    "axes[1][0].set_title('доход заёмщика')\n",
    "\n",
    "axes[1][1].hist(df['bki_request_cnt'])\n",
    "axes[1][1].set_title('количество запросов в БКИ')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Из гистограмм выше кажется, что выбросы есть, но их немного. \n",
    "# Однако я написал класс, который покажет более точную информацию.\n",
    "outliers.find(df[num_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Если судить по цифрам, то выбросов везде, кроме age, оказывается весьма ощутимое количество. \n",
    "# В общей сумме это больше четверти всего датасета. Попробуем поискать выбросы в тех же данных, \n",
    "# но логарифмированных.\n",
    "outliers.find(np.log(df[num_cols]+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ситуация стала получше везде, кроме признака decline_app_cnt. Попробуем оставить это как есть \n",
    "# и логарифмируем все признаки\n",
    "df['age'] = np.log(df['age']+1)\n",
    "df['bki_request_cnt'] = np.log(df['bki_request_cnt']+1)\n",
    "df['income'] = np.log(df['income']+1)\n",
    "df['decline_app_cnt'] = np.log(df['decline_app_cnt']+1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Оценим важность числовых признаков\n",
    "imp_num = Series(f_classif(df[num_cols], df['default'])[0], index = num_cols)\n",
    "imp_num.sort_values(inplace = True)\n",
    "imp_num.plot(kind = 'barh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Оценим важность бинарных признаков\n",
    "imp_num = Series(f_classif(df[bin_cols], df['default'])[0], index = bin_cols)\n",
    "imp_num.sort_values(inplace = True)\n",
    "imp_num.plot(kind = 'barh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Самый значительный - decline_app_cnt\n",
    "# Теперь посмотрим матрицу корреляци для числовых признаков.\n",
    "plt.figure(figsize=(10,5))\n",
    "sns.heatmap(df[num_cols].corr().abs(), vmin=0, vmax=1, annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Явных корреляций здесь нет.Теперь посмотрим корреляции признаков дат\n",
    "plt.figure(figsize=(10,5))\n",
    "sns.heatmap(df[date_cols].corr().abs(), vmin=0, vmax=1, annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Явно видно, что с признаками дат мы переборщили. Уберем weekofyear, quarter, dayofyear:\n",
    "df = df.drop(['weekofyear'],axis=1)\n",
    "df = df.drop(['quarter'],axis=1)\n",
    "df = df.drop(['dayofyear'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Атуализируем группы\n",
    "bin_cols = ['sex','car','car_type','good_work','foreign_passport']\n",
    "cat_cols = ['home_address']\n",
    "num_cols = ['age','decline_app_cnt','income','bki_request_cnt']\n",
    "\n",
    "# Признаки, получившиеся в результате преобразования даты, выделим в отдельную категорию\n",
    "date_cols = ['month','day','week','dayofweek'] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Подготовка модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Прежде всего вернем в датасет признак ClientID:\n",
    "\n",
    "df['client_id'] = clients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Разделим датасет обратно на тестовые и тренировочные данные. \n",
    "# Обучение и тестирование модели будет производиться на тренировочных данных. \n",
    "# Из тестового датасета отдельно сохраним данные с клиентскими id\n",
    "\n",
    "df_train = df.query('sample == 1').drop(['sample', 'client_id'], axis=1)\n",
    "df_test = df.query('sample == 0').drop(['sample', 'default'], axis=1)\n",
    "\n",
    "y = df_train.default.values           \n",
    "X = df_train.drop(['default'], axis=1).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=RANDOM_SEED)\n",
    "df_test.shape, df_train.shape, X.shape, X_train.shape, X_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(random_state=RANDOM_SEED, max_iter = 1000)\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred_prob = model.predict_proba(X_valid)[:,1]\n",
    "y_pred = model.predict(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Метрики качества\n",
    "metrics = ['accuracy', 'precision', 'recall', 'f1_score']\n",
    "value = [accuracy_score(y_valid,y_pred), precision_score(y_valid,y_pred), recall_score(y_valid,y_pred),\n",
    "         f1_score(y_valid,y_pred)]\n",
    "first_metrics_df = pd.DataFrame({'Метрика': metrics, 'Значение': value}, columns=['Метрика', 'Значение'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Кривая ROC-AUC\n",
    "fpr, tpr, threshold = roc_curve(y_valid, y_pred_prob)\n",
    "roc_auc = roc_auc_score(y_valid, y_pred_prob)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot([0, 1], label='Baseline', linestyle='--')\n",
    "plt.plot(fpr, tpr, label = 'Regression')\n",
    "plt.title('Logistic Regression ROC AUC = %0.3f' % roc_auc)\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.legend(loc = 'lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Матрица ошибок\n",
    "tn, fp, fn, tp = confusion_matrix(y_valid, y_pred).ravel()\n",
    "print(tp, fp) \n",
    "print(fn, tn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Хотя ROC-AUC дал неплохой результат, мы абсолютно не угадали дефолтных клиентов. \n",
    "# Посмотрим на PRC-AUC, поскольку данная метрика может оценивать эффективность алгоритма на несбалансированных данных\n",
    "precision, recall, thresholds = precision_recall_curve(y_valid, y_pred_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "prc_area = auc(recall, precision)\n",
    "plt.plot(recall, precision, lw=3, label='площадь под PR кривой = %0.3f)' % prc_area)\n",
    "    \n",
    "plt.xlim([-.05, 1.0])\n",
    "plt.ylim([-.05, 1.05])\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Precision-Recall Curve')\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Добавим метрики в наш датасет метрик для первой модели\n",
    "\n",
    "add_metrics = pd.DataFrame({'Метрика': ['ROC_AUC', 'PRC_AUC'], 'Значение':\n",
    "                            [roc_auc, prc_area]}, columns=['Метрика', 'Значение'])\n",
    "\n",
    "first_metrics_df = first_metrics_df.append(add_metrics, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# f1_score = 0.038 recall = 0.022. Имеем ошибку второго рода. \n",
    "# В данном случае метрика ROC-AUC (= 0.743) не показательна, \n",
    "# поскольку мы имеем дело с несбалансированной моделью.\n",
    "# Попробуем подобрать параметры вручную\n",
    "\n",
    "model = LogisticRegression(random_state=RANDOM_SEED)\n",
    "\n",
    "iter_max = 100\n",
    "\n",
    "param_grid = [\n",
    "    {'penalty': ['l1'], \n",
    "     'solver': ['liblinear', 'lbfgs'], \n",
    "     'class_weight':['none', 'balanced'], \n",
    "     'multi_class': ['auto','ovr'], \n",
    "     'max_iter':[iter_max]},\n",
    "    {'penalty': ['l2'], \n",
    "     'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'], \n",
    "     'class_weight':['none', 'balanced'], \n",
    "     'multi_class': ['auto','ovr'], \n",
    "     'max_iter':[iter_max]},\n",
    "    {'penalty': ['none'], \n",
    "     'solver': ['newton-cg', 'lbfgs', 'sag', 'saga'], \n",
    "     'class_weight':['none', 'balanced'], \n",
    "     'multi_class': ['auto','ovr'], \n",
    "     'max_iter':[iter_max]},\n",
    "]\n",
    "\n",
    "gridsearch = GridSearchCV(model, param_grid, scoring='f1', n_jobs=-1)\n",
    "gridsearch.fit(X_train, y_train)\n",
    "model = gridsearch.best_estimator_\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Обучим модель на данных и проверим confusion_matrix\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred_prob = model.predict_proba(X_valid)[:,1]\n",
    "y_pred = model.predict(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# матрица ошибок\n",
    "tn, fp, fn, tp = confusion_matrix(y_valid, y_pred).ravel()\n",
    "print(tp, fp) \n",
    "print(fn, tn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuracy: %.4f' % accuracy_score(y_valid, y_pred))\n",
    "print('Precision: %.4f' % precision_score(y_valid, y_pred))\n",
    "print('Recall: %.4f' % recall_score(y_valid, y_pred))\n",
    "print('F1: %.4f' % f1_score(y_valid, y_pred))\n",
    "\n",
    "precision, recall, thresholds = precision_recall_curve(y_valid, y_pred_prob)\n",
    "print('ROC_AUC = ', round(roc_auc_score(y_valid, y_pred_prob), 4))\n",
    "print('PRC_AUC = ', round(auc(recall, precision), 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Метрики первой модели\n",
    "first_metrics_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Итог"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Изначально данные были плохо сбалансированы, и строить адекватных прогнозов по ним не получалось. \n",
    "# Однако, с помощью GridSearchCV, удалось найти оптимальные параметры, которые обеспечили приемлимые значения метрик."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
